{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def map_nested_fn(fn):\n",
    "  '''Recursively apply `fn` to key-value pairs of a nested dict.'''\n",
    "  def map_fn(nested_dict):\n",
    "    return {k: (map_fn(v) if isinstance(v, dict) else fn(k, v))\n",
    "            for k, v in nested_dict.items()}\n",
    "  return map_fn\n",
    "\n",
    "params = {'linear_1': {'w': jnp.zeros((5, 6)), 'b': jnp.zeros(5)},\n",
    "          'linear_2': {'w': jnp.zeros((6, 1)), 'b': jnp.zeros(1)}}\n",
    "gradients = jax.tree.map(jnp.ones_like, params)  # dummy gradients\n",
    "\n",
    "label_fn = map_nested_fn(lambda k, _: k)\n",
    "tx = optax.partition(\n",
    "    {'w': optax.adam(1.0), 'b': optax.sgd(1.0)}, label_fn)\n",
    "state = tx.init(params)\n",
    "updates, new_state = tx.update(gradients, state, params)\n",
    "new_params = optax.apply_updates(params, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = np.load('./results/repl_uci/mclmc_debug_20250305-140952/warmstart/params_0.npz')\n",
    "with open(\"params_end.txt\", \"w\") as f:\n",
    "    for k, v in params.items():\n",
    "        f.write(f\"{k}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_layer0(params):\n",
    "    if 'layer0' in params:\n",
    "        del params['layer0']\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, dict):\n",
    "            delete_layer0(value)\n",
    "    return params\n",
    "params = {'fcn':{'layer0':{'kernel':1, 'bias':2}, 'layer1':{'kernel':3, 'bias':4}}}\n",
    "params = delete_layer0(params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_params(params):\n",
    "    input_output_layers = {}\n",
    "    hidden_layers = {}\n",
    "\n",
    "    input_output_layers = {}\n",
    "    hidden_layers = {}\n",
    "\n",
    "    for key, value in params['fcn'].items():\n",
    "        if key == 'layer0' or key == f'layer{len(params[\"fcn\"]) - 1}':\n",
    "            input_output_layers[key] = value\n",
    "        else:\n",
    "            hidden_layers[key] = value\n",
    "\n",
    "    return {'fcn': input_output_layers}, {'fcn': hidden_layers}\n",
    "params = {'fcn':{'layer0':{'kernel':1, 'bias':2}, 'layer1':{'kernel':3, 'bias':4}, 'layer2':{'kernel':5, 'bias':6}}}\n",
    "a,b = partition_params(params)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from flax import traverse_util\n",
    "import jax.lax as lax\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "def loss_fn(params, x, y):\n",
    "    preds = model.apply(params, x)\n",
    "    loss = jnp.mean((preds - y) ** 2)\n",
    "    return loss\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.ndarray):\n",
    "        x = nn.Dense(features=5)(x)\n",
    "        x = lax.stop_gradient(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1)(x)\n",
    "        return x\n",
    "    \n",
    "model = FCN()\n",
    "x = jnp.ones((10, 5))\n",
    "params = model.init(jax.random.PRNGKey(0), x)\n",
    "print(params)\n",
    "y = jnp.ones((10, 1))\n",
    "grads = jax.grad(loss_fn)(params, x, y)\n",
    "optimizer = optax.adam(1e-3)\n",
    "# Create a training state\n",
    "class TrainState(train_state.TrainState):\n",
    "    params: dict\n",
    "\n",
    "state = TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
    "\n",
    "# Update the parameters\n",
    "state = state.apply_gradients(grads=grads)\n",
    "\n",
    "print(state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartitionFCN(nn.Module):\n",
    "    @nn.compact\n",
    "    def some_filter_fn(k):\n",
    "        if k == 'Dense_0':\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def selective_stop_grad(self,variables):\n",
    "        flat_vars = traverse_util.flatten_dict(variables)\n",
    "        new_vars = {k: lax.stop_gradient(v) if self.some_filter_fn(k) else v for k, v in flat_vars.items()}\n",
    "        return traverse_util.unflatten_dict(new_vars)\n",
    "    \n",
    "    def setup(self):\n",
    "        _FCN = nn.map_variables(FCN, \"params\", self.selective_stop_grad)\n",
    "        self.fcn = _FCN()    \n",
    "        \n",
    "    def __call__(self, x: jnp.ndarray):\n",
    "      return self.fcn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.core import freeze, unfreeze\n",
    "for name, param in unfreeze(params).items():\n",
    "    print(f\"Parameter name: {name}, value: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('results/dataset/partition_warmstart_0/samples/0/sample_0.npz')\n",
    "print(data)\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import blackjax\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.lax as lax\n",
    "\n",
    "# Define 2D Gaussian log probability function\n",
    "def log_prob_fn(x):\n",
    "    # Mean at origin, unit variance\n",
    "    return -0.5 * jnp.sum(x[0]**2) \n",
    "\n",
    "# Initialize random key\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "\n",
    "\n",
    "\n",
    "# Initial position\n",
    "init_position = jnp.array([jax.random.normal(rng_key), jax.random.normal(rng_key)])\n",
    "\n",
    "# Initialize MCLMC sampler\n",
    "kernel = blackjax.mcmc.mclmc.build_kernel(\n",
    "    logdensity_fn=log_prob_fn,\n",
    "    sqrt_diag_cov=jnp.ones(2),\n",
    "    integrator=blackjax.mcmc.integrators.isokinetic_mclachlan\n",
    ")\n",
    "\n",
    "state = blackjax.mcmc.mclmc.init(\n",
    "    position=init_position,\n",
    "    logdensity_fn=log_prob_fn,\n",
    "    rng_key=rng_key\n",
    ")\n",
    "\n",
    "# Run sampler\n",
    "n_samples = 1000\n",
    "samples = []\n",
    "rng_key, sample_key = jax.random.split(rng_key)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    rng_key, step_key = jax.random.split(rng_key)\n",
    "    state, info = kernel(step_key, state, L=0.5, step_size=0.1)\n",
    "    samples.append(state.position)\n",
    "\n",
    "samples = jnp.array(samples)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(samples[:,0], samples[:,1], alpha=0.1)\n",
    "plt.title('MCLMC Samples from 2D Standard Normal')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y') \n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Plot marginal histograms\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.hist(samples[:,0], bins=50, density=True)\n",
    "plt.title('Marginal Distribution (x)')\n",
    "plt.subplot(122) \n",
    "plt.hist(samples[:,1], bins=50, density=True)\n",
    "plt.title('Marginal Distribution (y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "def fn(x,y,z):\n",
    "    return x+y+z\n",
    "\n",
    "fn = partial(fn, y=1)\n",
    "fn = partial(fn, z=2)\n",
    "fn(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
